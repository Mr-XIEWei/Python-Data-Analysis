{"_id":"note:gLklzL4h7","title":"数据表处理","content":"# 数据清洗之数据表处理\n```Python\nimport pandas as pd\nimport numpy as np\nimport os\nos.chdir('/Users/waynexie/Documents/程序员/数据清洗课程材料/代码和数据')\ndf = pd.read_csv('baby_trade_history.csv', encoding='utf-8',dtype={'user_id':str})\n```\n## 数据筛选\n\n- 在数据中,选择需要的行或者列\n```Python\ndf.info()\ndf.head(5) #查看前5行\ndf.tail(5) #查看后5行\ndf.columns #查看变量名称\n```\n- 基础索引方式,就是直接引用\n```Python\ndf['user_id']\ndf['user_id'][1:5]# 第二行到第五行\n# 多个变量选择\ndf[['user_id','buy_mount','day']][:5]   \n```\n- loc[行索引名称或者条件,列索引名称或者标签] \n- iloc[行索引位置,列索引位置]\n- 注意, 区分loc和iloc\n```Python\ndf.loc[3:4]# 选择行索引标签\ndf.loc[:,['user_id','buy_mount']]#选择某两列\ndf.loc[1:3,['user_id','buy_mount']] #loc在这里选择的是行索引标签\ndf.loc[df.user_id =='786295544',['user_id','buy_mount','day']]\ndf.loc[(df.user_id =='786295544') | (df.user_id =='444069173'),['user_id','buy_mount','day']]# 多个条件选择,|代表或\n```\n```Python\n#注意iloc是位置\ndf.iloc[:,1:4] #按照位置来选择第二列到第四列\ndf.iloc[:,[0,2]] # 按照位置来选择第1列和第3列\ndf.iloc[3,[1,2]] #选择第4行，第2列和第3列数据, 这里的3代表的不是索引标签而是位置\ndf.iloc[2:7,[1,2]] #选择第3行到第7行，第2列和第3列数据\n```\n- 注意loc和iloc的区别\n```Python\ndf.loc[2:7]#标签是2-7的行\ndf.iloc[2:7]#位置是3-7的行\n```\n\n## 数据增加和删除\n\n- 在数据中,直接添加列\n```Python\n#增加一列,购买量,购买量超过3的为高，低于3的为底\ndf['购买量'] = np.where(df['buy_mount'] >3,'高','低')\ndf\n# 增加行在dataframe中不常用，后面会用其他方法实现\n# 可以使用append方法在 dataframe末尾实现\n```\n- 使用df.insert方法在数据中添加一列\n\t- df.insert(位置,变量名称，值) \n```Python\n# 先将这一列取出来，赋值给对象auction_id,然后在数据中删除这一列，再将其添加进去\nauction_id = df['auction_id']\ndel df['auction_id']\ndf.insert(0, 'auction_id', auction_id)\ndf.head(5)\n```\n- 掌握drop(labels,axis,inplace=True) 的用法\n- labels表示删除的数据, axis表示作用轴，inplace=True表示是否对原数据生效 \n- axis=0按行操作, axis=1按列操作\n- 使用del函数直接删除其中一列\n```Python\n# 删除这两列,加inplace代表是否在原数据上操作,1代表沿着列的方向\n# 同时删除多个变量，需要以列表的形式\n# 注意inplace =True,代表是否对原数据操作, 否则返回的是视图，并没有对原数据进行操作\n# labels表示删除的数据, axis表示作用轴，inplace=True表示是否对原数据生效,\n# axis=0按行操作, axis=1按列操作\ndf.drop(labels = ['property', '购买量'],axis = 1,inplace=True) #删除这两列,加inplace代表是否在原数据上操作, 1代表沿着列的方向\n# 按行删除法\ndf.drop(labels = [3,4],inplace = True,axis= 0) # 删除索引标签3和4对应的行\ndf.drop(labels= range(6,11),axis=0,inplace=True)  #删除索引名称6到10,注意range迭代器产生的是6到10\n# 查看\ndf\n```\n![](2020-09-26---4-46-12-kfjfjfjl.png)\n\n## 数据修改和查找\n\n- 使用loc方法修改数据\n- 使用loc方法查找符合条件的数据\n\n```Python\ndf1 = pd.read_csv('sam_tianchi_mum_baby.csv',encoding = 'utf-8',dtype =str)\ndf1.head(5)\n# 将gender为0的改为女性，1改为男性，2改为未知\ndf1.loc[df['gender'] =='0','gender'] ='女性'\ndf1.loc[df['gender'] =='1','gender'] ='男性'\ndf1.loc[df['gender'] =='2','gender'] ='未知'\ndf1.head(10)\n```\n- 在数据中, 可以使用rename修改列名称或者行索引名称 \n```Python\n# 修改列标签和行索引名称\ndf1.rename(columns = {'user_id':'用户ID','birthday':'出生日期','gender':'性别'},inplace = True)\ndf1.rename(index = {1:'one',10:'ten' },inplace = True) #修改行索引名称\ndf1.reset_index(drop=True,inplace=True)# 重置索引\ndf1.head(10)\n```\n- 查询\n- 条件与条件之间用&或者|连接，分别代表‘且’和‘或’\n- 使用between和isin选择满足条件的行\n```Python\n# 条件查询\ndf[df.buy_mount > 3] #性别等于未知\ndf.loc[df.buy_mount > 3,:]#与上面相同\ndf[~(df.buy_mount > 3)] # ~代表非\ndf[ (df.buy_mount > 3) &  (df.day > 20140101)] # 多条件查询\n#使用between,inclusive=True代表包含两端\ndf[ df['buy_mount'].between(4,10,inclusive=True)]\n# 使用pd.isin()方法\n# 包含\ndf[df['auction_id'].isin([41098319944, 17916191097,21896936223])]\n```\n\n## 数据整理\n- 在数据清洗过程中,很多时候需要将不用的数据整理在一起 ，方便后续的分析，这个过程也叫数据合并\n- 常见的合并方法有堆叠和按主键进行合并，堆叠又分为横向 堆叠和纵向堆叠，按主键合并类似于sql里面的关联操作\n- 横向堆叠将两张表或多张表在X轴方向，即横向拼接在一起\n- 纵向堆叠将两张表或多张表在Y轴方向，即纵向拼接在一起\n- 注意使用concat时,axis =1用于横向，0代表纵向\n- 注意join取inner或者outer时，分别代表交集和并集\n```Python\nimport xlrd\nworkbook = xlrd.open_workbook('meal_order_detail.xlsx')\nsheet_name = workbook.sheet_names() #返回所有sheet的列表\nsheet_name\norder1 = pd.read_excel('meal_order_detail.xlsx',sheet_name ='meal_order_detail1')\norder2 = pd.read_excel('meal_order_detail.xlsx',sheet_name ='meal_order_detail2')\norder3 = pd.read_excel('meal_order_detail.xlsx',sheet_name ='meal_order_detail3')\norder = pd.concat([order1,order2,order3],axis=0,ignore_index=True)# 忽略原来的索引\n```\n```Python\n# 通过循环方式进行合并\nbasic = pd.DataFrame()\nfor i in sheet_name:\n    basic_i = pd.read_excel('meal_order_detail.xlsx', header = 0,sheet_name=i,encoding='utf-8')\n    basic = pd.concat([basic,basic_i],axis=0,ignore_index=True)\nbasic.shape\n```\n![](2020-09-26---7-44-25-kfjlwmqf.png)\n\n- 关联\n\t- 关联字段必须类型一致\n\t- 左连接说明左边表全都要，右边表匹配到的才要\n```Python\ndf = pd.read_csv('baby_trade_history.csv', encoding='utf-8',dtype={'user_id':str})# 交易数据\ndf1 = pd.read_csv('sam_tianchi_mum_baby.csv',encoding = 'utf-8',dtype =str)#婴儿信息\ndf2 = pd.merge(left = df, right=df1,  how='inner',  left_on='user_id', right_on = 'user_id')# 内连接\ndf2.head(10)\n```\n> **说明**：详解pd.merge函数\n> \n```Python\npd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n         left_index=False, right_index=False, sort=True,\n         suffixes=('_x', '_y'), copy=True, indicator=False,\n         validate=None)\n```\n参数如下：\n- left: 拼接的左侧DataFrame对象\n- right: 拼接的右侧DataFrame对象\n- on: 要加入的列或索引级别名称。 必须在左侧和右侧DataFrame对象中找到。 如果未传递且left_index和right_index为False，则DataFrame中的列的交集将被推断为连接键。\n- left_on:左侧DataFrame中的列或索引级别用作键。 可以是列名，索引级名称，也可以是长度等于DataFrame长度的数组。\n- right_on: 左侧DataFrame中的列或索引级别用作键。 可以是列名，索引级名称，也可以是长度等于DataFrame长度的数组。\n- left_index: 如果为True，则使用左侧DataFrame中的索引（行标签）作为其连接键。 对于具有MultiIndex（分层）的DataFrame，级别数必须与右侧DataFrame中的连接键数相匹配。\n- right_index: 与left_index功能相似。\n- how: One of ‘left’, ‘right’, ‘outer’, ‘inner’. 默认inner。inner是取交集，outer取并集。比如left：[‘A’,‘B’,‘C’];right[’'A,‘C’,‘D’]；inner取交集的话，left中出现的A会和right中出现的买一个A进行匹配拼接，如果没有是B，在right中没有匹配到，则会丢失。'outer’取并集，出现的A会进行一一匹配，没有同时出现的会将缺失的部分添加缺失值。![](2020-09-26---7-40-28-kfjlrlvf.png)![](2020-09-26---7-41-59-kfjlthxj.png)\n- sort: 按字典顺序通过连接键对结果DataFrame进行排序。 默认为True，设置为False将在很多情况下显着提高性能。\n- suffixes: 用于重叠列的字符串后缀元组。 默认为（‘x’，’ y’）。\n- copy: 始终从传递的DataFrame对象复制数据（默认为True），即使不需要重建索引也是如此。\n- indicator:将一列添加到名为_merge的输出DataFrame，其中包含有关每行源的信息。 _merge是分类类型，并且对于其合并键仅出现在“左”DataFrame中的观察值，取得值为left_only，对于其合并键仅出现在“右”DataFrame中的观察值为right_only，并且如果在两者中都找到观察点的合并键，则为left_only。\n\n## 层次化索引\n在一个轴上拥有两个或者两个以上的索引 \n- 使用loc语句进行访问\n- loc里面接受tuple,如loc[(a,b),:]\n\n```Python\ndf = pd.read_csv('baby_trade_history.csv', encoding='utf-8',dtype={'user_id':str},index_col=[3,0])#将数据第4列和第1列当成索引\ndf.loc[28] #第一层引用\ndf.loc[28].loc[[82830661,532110457]]#第二层引用\n直接引用两层\ndf3.loc[(a,b),:] #a和b分别代表第一层和第二层的索引\n接受tuple\ndf.loc[(28,[82830661,532110457]),:]# 第二层索引选择，多个选择\ndf.loc[(28,[82830661,532110457]),['auction_id','cat_id']]# 第二层索引选择，选择2个变量\ndf.loc[([28,50014815])] #第一层索引为28和50014815\n```","tags":[],"folderPathname":"/数据清洗","data":{},"createdAt":"2020-09-26T07:51:38.527Z","updatedAt":"2020-09-26T12:01:54.103Z","trashed":false,"_rev":"Ksvm-0vuA"}