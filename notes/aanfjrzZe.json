{"_id":"note:aanfjrzZe","title":"文件读写","content":"# 数据清洗之文件读写\n\n## 准备工作\n```Python\nimport pandas as pd#读写文件用到pandas库\nimport numpy as np\nimport os# 更改文件路径\nos.chdir('/Users/waynexie/Documents/程序员/数据清洗课程材料/代码和数据')\nos.getcwd()\n#设置最大显示列数\npd.set_option('display.max_columns', 20)\n#设置最大显示行数\npd.set_option('display.max_rows', 100)\n```\n\n## csv文件读写\n\n- pandas内置了10多种数据源读取函数,常见的就是CSV和EXCEL • 使用read_csv方法读取，结果为dataframe格式\n- 在读取csv文件时，文件名称尽量是英文\n- 参数较多，可以自行控制，但很多时候用默认参数\n- 读取csv时，注意编码，常用编码为utf-8、gbk 、gbk2312和gb18030等 \n\n```Python\n# 婴儿信息表\nbaby = pd.read_csv('sam_tianchi_mum_baby.csv', encoding='utf-8')#默认将第一行作为表头,一般用utf-8编码\nbaby.head(10)\n# 编码为gbk中文编码\n# 订单数据\norder = pd.read_csv('meal_order_info.csv',encoding =  'gbk', dtype = {'info_id':str,'emp_id':str})#dtype更改某一列数据类型\norder.info()#查看列标签字段信息，如数据类型等\n#交易表\nbaby_trade_history = pd.read_csv('baby_trade_history.csv', nrows=100) #读取前100行\n```\n- 使用to_csv方法快速保存\n```Python\nbaby_trade_history.to_csv('a1.csv',encoding='utf-8',index=False)#建议用utf-8编码或者中文gbk编码,默认是utf-8编码,index=False表示不写出索引行\n#会自动保存到当前路径下\n```\n\n## Excel文件读写\n\n- 使用read_excel读取,读取后的结果为dataframe格式\n- 读取excel文件和csv文件参数大致一样, 但要考虑工作表sheet页\n- 参数较多，可以自行控制，但很多时候用默认参数\n- 读取excel时，注意编码，常用编码为utf-8、gbk 、gbk2312和gb18030等 \n- python3中read_excel无encoding参数\n```Python\n# 订单数据\ndf1 = pd.read_excel('meal_order_detail.xlsx',encoding = 'utf-8',sheet_name = 'meal_order_detail1')# 读取excel需要注明具体哪一个工作簿,否则就是第一个工作簿\ndf1 = pd.read_excel('meal_order_detail.xlsx',encoding = 'utf-8',sheet_name = 0)# sheet_name可以为数字，代表第几个工作簿\n```\n- 使用to_excel快速保存为xlsx格式\n\n```Python\ndf1.to_excel('a1.xlsx',sheet_name='one',index=False)\n```\n\n## 数据库文件读写\n\n- 使用sqlalchemy建立连接\n- 需要知道数据库的相关参数，如数据库IP地址、用户名和密码等 \n```Python\n#导入相关库\nimport pymysql\nfrom sqlalchemy import create_engine\n```\n- 按实际情况依次填写MySQL的用户名、密码、IP地址、端口、数据库名\n\t- create_engine('mysql+pymysql://user:passward@IP:3306/test01')\n\t- root 用户名\n\t- passward --密码\n\t- IP : 服务区IP\n\t- 3306： 端口号\n\t- test01 :数据库名称\n```Python\n# 建立连接\nconn = create_engine('mysql+pymysql://root:1234567890@localhost:3306/myemployees')\n```\n- 通过pandas中read_sql 函数读入, 读取完以后是dataframe格式 \n```Python\n# 读取数据\nsql = 'select * from departments'  #选择数据库中表名称\ndf1 = pd.read_sql(sql,conn)\n#df1 是个dataframe格式\n#编写函数与mysql中的表建立连接\ndef query(table):\n    host = 'localhost'\n    user = 'root'\n    password = '1234567890'\n    database = 'myemployees'\n    port = 3306\n    conn = create_engine(\"mysql+pymysql://{}:{}@{}:{}/{}\".format(user, password, host, port, database))\n    #SQL语句，可以定制，实现灵活查询\n    sql = 'select * from ' + table  #选择数据库中表名称\n    # 使用pandas 的read_sql函数，可以直接将数据存放在dataframe中\n    results = pd.read_sql(sql,conn)\n    return results\ndf2 =  query('departments')\n```\n- 通过dataframe的to_sql方法保存\n\t- df.to_sql(name, con=engine, if_exists='replace/append/fail',index=False)\n\t- name是表名\n\t- con是连接\n\t- if_exists：表如果存在怎么处理 -- append：追加 -- replace：删除原表，建立新表再添加 -- fail：什么都不干\n\t- index=False：不插入索引index\n```Python\nimport os\nos.chdir('/Users/waynexie/Documents/程序员/数据清洗课程材料/代码和数据')\ndf = pd.read_csv('baby_trade_history.csv')\ntry:\n    df.to_sql('testdf',con = conn, index= False,if_exists= 'replace')\nexcept:\n    print('error')\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":[],"folderPathname":"/数据清洗","data":{},"createdAt":"2020-09-26T05:04:30.624Z","updatedAt":"2020-09-26T11:05:37.569Z","trashed":false,"_rev":"E51ftl3KG"}